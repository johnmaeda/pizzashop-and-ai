{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§‘â€ðŸ³ A kitchen that responds to your â€œIâ€™m hungryâ€ is more than feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Get a kernel ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is second nature to you now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenaicompletion\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel.add_text_embedding_generation_service(\"azureopenaiembedding\", AzureTextEmbedding(\"text-embedding-ada-002\", endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openaicompletion\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    kernel.add_text_embedding_generation_service(\"openaiembedding\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¦„ Find the right function for me, and then use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be doing two things:\n",
    "\n",
    "1. Let the `ActionPlanner` know what skills are available to it.\n",
    "2. Give it a goal formed as an `ask`.\n",
    "3. Have it find the most similar function that can get the job done.\n",
    "4. Make it so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import ActionPlanner\n",
    "\n",
    "planner = ActionPlanner(kernel)\n",
    "\n",
    "from semantic_kernel.core_skills import FileIOSkill, MathSkill, TextSkill, TimeSkill\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(FileIOSkill(), \"fileIO\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "kernel.import_skill(TextSkill(), \"text\")\n",
    "\n",
    "ask = \"What is the sum of 110 and 990?\"\n",
    "\n",
    "print(f\"ðŸ§² Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"ðŸ§² The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n",
    "\n",
    "result = await plan.invoke_async()\n",
    "display(Markdown(f\"## âœ¨ For the ask '{ask}'\"))\n",
    "print(f\"âœ¨ The generated result is: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `ActionPlanner` isn't much of a planner â€” it's more of an automatic function selector. If you want to imagine a plan as a sequence of steps, and at each step using a different automatically selected function, let's keep going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¦„ Generate a multi-step plan and execute it\n",
    "\n",
    "Let's show you the `SequentialPlanner` which generates a plan more like you expect. As of August 2023 our most advanced C#-based `StepwisePlanner` is not available in our Python package, but it soon will be. How's it different? Well, it's a lot more sophisticated â€” and more importantly, it is more clever at giving you what you have `ask`-ed for :+).\n",
    "\n",
    "You can trace the steps of the `SequentialPlanner` by setting `trace_resultsp` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "plugins_directory = \"./plugins-sk\"\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(plugins_directory, \"LiterateFriend\")\n",
    "\n",
    "# create an instance of sequential planner.\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# the ask for which the sequential planner is going to find a relevant function.\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\"\"\"\n",
    "\n",
    "# ask the sequential planner to identify a suitable function from the list of functions available.\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "# ask the sequential planner to execute the identified function.\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(f\"âœ… Step {index+1} used function `{step._function.name}`\")\n",
    "\n",
    "trace_resultp = False\n",
    "\n",
    "if trace_resultp:\n",
    "    print(\"Longform trace:\\n\")\n",
    "    for index, step in enumerate(plan._steps):\n",
    "        print(\"Step:\", index)\n",
    "        print(\"Description:\",step.description)\n",
    "        print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "        print(\"Input vars:\", step._parameters._variables)\n",
    "        print(\"Output vars:\", step._outputs)\n",
    "        if len(step._outputs) > 0:\n",
    "            print( \"  Output:\\n\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n  \"))\n",
    "\n",
    "display(Markdown(f\"## âœ¨ Generated result from the ask: {ask}\\n\\n---\\n\" + str(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”– There are a variety of limitations to using the planner in August of 2023 in terms of number of tokens required and model preference that we can expect to slowly vanish over time. For simple tasks, this Planner-based approach is unusually powerful. It takes full advantage of both COMPLETION and SIMILARITY in a truly magical way.\n",
    "\n",
    "![](assets/twodimensions.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
