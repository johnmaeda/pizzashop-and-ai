{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5 Using vector memory store to assemble coherent \"what-if\" scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Get a kernel ready with a vector memory store\n",
    "\n",
    "We're going to create a kernel that includes an embedding generation service ‚Äî so that we can best construct the context that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==0.3.8.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "# Configure AI services used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", AzureTextEmbedding(\"text-embedding-ada-002\", api_key, endpoint))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    kernel.add_text_embedding_generation_service(\"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéóÔ∏è Prepare a native memory bank of information we like to remember\n",
    "\n",
    "We store the SWOT information in \"conventional\" arrays in Python that are not \"semantic\" in nature. That said, they're still eminently useful for the kind of computations we'll play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_questions = [\"What unique recipes or ingredients does the pizza shop use?\",\"What are the skills and experience of the staff?\",\"Does the pizza shop have a strong reputation in the local area?\",\"Are there any unique features of the shop or its location that attract customers?\", \"Does the pizza shop have a strong reputation in the local area?\", \"Are there any unique features of the shop or its location that attract customers?\"]\n",
    "weakness_questions = [\"What are the operational challenges of the pizza shop? (e.g., slow service, high staff turnover)\",\"Are there financial constraints that limit growth or improvements?\",\"Are there any gaps in the product offering?\",\"Are there customer complaints or negative reviews that need to be addressed?\"]\n",
    "opportunities_questions = [\"Is there potential for new products or services (e.g., catering, delivery)?\",\"Are there under-served customer segments or market areas?\",\"Can new technologies or systems enhance the business operations?\",\"Are there partnerships or local events that can be leveraged for marketing?\"]\n",
    "threats_questions = [\"Who are the major competitors and what are they offering?\",\"Are there potential negative impacts due to changes in the local area (e.g., construction, closure of nearby businesses)?\",\"Are there economic or industry trends that could impact the business negatively (e.g., increased ingredient costs)?\",\"Is there any risk due to changes in regulations or legislation (e.g., health and safety, employment)?\"]\n",
    "\n",
    "strengths = [ \"Unique garlic pizza recipe that wins top awards\",\"Owner trained in Sicily at some of the best pizzerias\",\"Strong local reputation\",\"Prime location on university campus\" ]\n",
    "weaknesses = [ \"High staff turnover\",\"Floods in the area damaged the seating areas that are in need of repair\",\"Absence of popular calzones from menu\",\"Negative reviews from younger demographic for lack of hip ingredients\" ]\n",
    "opportunities = [ \"Untapped catering potential\",\"Growing local tech startup community\",\"Unexplored online presence and order capabilities\",\"Upcoming annual food fair\" ]\n",
    "threats = [ \"Competition from cheaper pizza businesses nearby\",\"There's nearby street construction that will impact foot traffic\",\"Rising cost of cheese will increase the cost of pizzas\",\"No immediate local regulatory changes but it's election season\" ]\n",
    "\n",
    "print(\"‚úÖ SWOT analysis for the pizza shop is resident in native memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üò∂‚Äçüå´Ô∏è Use \"semantic\" memory to hold onto this information so that it can be searched by meaning\n",
    "\n",
    "And to store the information semantically, we use the text embedding model added to the kernel to convert text into long vectors of numbers. We only need to do this once. But note that unless we have a \"vector database\" wired into the kernel, the embedding calculations do not last beyond this notebook. That's why it's called a \"volatile\" memory store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryCollectionName = \"SWOT\"\n",
    "\n",
    "for i in range(len(strengths)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"strength-{i}\", text=f\"Internal business strength (S in SWOT) that makes customers happy and satisfied Q&A: Q: {strength_questions[i]} A: {strengths[i]}\")\n",
    "for i in range(len(weaknesses)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"weakness-{i}\", text=f\"Internal business weakness (W in SWOT) that makes customers unhappy and dissatisfied Q&A: Q: {weakness_questions[i]} A: {weaknesses[i]}\")\n",
    "for i in range(len(opportunities)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"opportunity-{i}\", text=f\"External opportunity (O in SWOT) for the business to gain entirely new customers Q&A: Q: {opportunities_questions[i]} A: {opportunities[i]}\")\n",
    "for i in range(len(threats)):\n",
    "    await kernel.memory.save_information_async(memoryCollectionName, id=f\"threat-{i}\", text=f\"External threat (T in SWOT) to the business that impacts its survival Q&A: Q: {threats_questions[i]} A: {threats[i]}\")\n",
    "\n",
    "print(\"üò∂‚Äçüå´Ô∏è Embeddings for SWOT have been generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that weaknesses and threats are v similar but strengths and weaknesses usually pertain to internal factors; whereas opportunities and threats pertain to external factors. Play around with the `potential_question` variable below to get a sense of how the embedding model does with comparing your `potential_question` to the vectors that have been computed and stored in the step above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "potential_question = \"what are easiest ways to make more money?\"\n",
    "counter = 0\n",
    "\n",
    "memories = await kernel.memory.search_async(memoryCollectionName, potential_question, limit=5, min_relevance_score=0.5)\n",
    "\n",
    "display(Markdown(f\"### ‚ùì Potential question: {potential_question}\"))\n",
    "\n",
    "for memory in memories:\n",
    "    if counter == 0:\n",
    "        related_memory = memory.text\n",
    "    counter += 1\n",
    "    print(f\"  > üò∂‚Äçüå´Ô∏è Similarity result {counter}:\\n  >> ID: {memory.id}\\n  Text: {memory.text}  Relevance: {memory.relevance}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of having a semantic memory bank like this means a lot can be done with your LLM AI that becomes more obvious to you with experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing all the Business Thinking and Design Thinking into semantic memory\n",
    "\n",
    "Let's take everything we have gathered thus far and put it into the semantic memory bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skillsDirectory = \"./plugins-sk\"\n",
    "\n",
    "pluginBT = kernel.import_semantic_skill_from_directory(skillsDirectory, \"BusinessThinking\");\n",
    "\n",
    "my_context = kernel.create_new_context()\n",
    "\n",
    "the_business = 'makes pizzas'\n",
    "my_context['input'] = the_business\n",
    "my_context['strengths'] = \", \".join(strengths)\n",
    "my_context['weaknesses'] = \", \".join(weaknesses)\n",
    "my_context['opportunities'] = \", \".join(opportunities)\n",
    "my_context['threats'] = \", \".join(threats)\n",
    "\n",
    "print(\"ü§ñ Computing cost efficiency...\")\n",
    "costefficiency_result = await kernel.run_async(pluginBT[\"SeekCostEfficiency\"], input_context=my_context)\n",
    "costefficiency_str = str(\"## Suggestions for how to gain cost efficiencies\\n\" + str(costefficiency_result))\n",
    "await kernel.memory.save_information_async(memoryCollectionName, id=\"costefficiency\", text=costefficiency_str)\n",
    "\n",
    "print(\"ü§ñ Computing time efficiency...\")\n",
    "timeefficiency_result = await kernel.run_async(pluginBT[\"SeekTimeEfficiency\"], input_context=my_context)\n",
    "timeefficiency_str = \"## Suggestions for how to gain time efficiencies\\n\"+str(timeefficiency_result)\n",
    "await kernel.memory.save_information_async(memoryCollectionName, id=\"timeefficiency\", text=timeefficiency_str)\n",
    "\n",
    "print(\"ü§ñ Computing business strategies overview...\")\n",
    "bizstrat_result = await kernel.run_async(pluginBT[\"BasicStrategies\"], input_context=my_context)\n",
    "bizstrat_str = \"# Business strategy thinking based on SWOT analysis\\n\"+str(bizstrat_result)\n",
    "await kernel.memory.save_information_async(memoryCollectionName, id=\"bizstrat\", text=bizstrat_str)\n",
    "\n",
    "customer_comments = \"\"\"\n",
    "Customer 1: The seats look really raggedy.\n",
    "Customer 2: The garlic pizza is the best on this earth.\n",
    "Customer 3: I've noticed that there's a new server every time I visit, and they're clueless.\n",
    "Customer 4: Why aren't there calzones?\n",
    "Customer 5: I love the garlic pizza and can't get it anywhere else.\n",
    "Customer 6: The garlic pizza is exceptional.\n",
    "Customer 7: Pizza can get a little messy so I prefer a calzone's neatness.\n",
    "Customer 8: Why is the pizza so expensive?\n",
    "Customer 9: There's no way to do online ordering.\n",
    "Customer 10: Why is the seating so uncomfortable and dirty?\n",
    "\"\"\"\n",
    "\n",
    "print(\"ü§ñ Computing design thinking interim results from customer comments ...\")\n",
    "pluginDT = kernel.import_semantic_skill_from_directory(skillsDirectory, \"DesignThinking\");\n",
    "my_result = await kernel.run_async(pluginDT[\"Empathize\"], pluginDT[\"Define\"], input_str=customer_comments)\n",
    "designthinking_str = \"# Categorized observations\\n\"+str(my_result)\n",
    "await kernel.memory.save_information_async(memoryCollectionName, id=\"designthinking\", text=designthinking_str)\n",
    "\n",
    "print(\"üò∂‚Äçüå´Ô∏è üéâ Memory is now flush with information :+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßê Put the accumulated memory to good use for \"what if\" scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_if_scenario = \"How can the business owner save time?\"\n",
    "counter = 0\n",
    "\n",
    "gathered_context = []\n",
    "max_memories = 3\n",
    "memories = await kernel.memory.search_async(memoryCollectionName, what_if_scenario, limit=max_memories, min_relevance_score=0.77)\n",
    "\n",
    "print(f\"ü§ñ Leveraging information available to address '{what_if_scenario}'...\")\n",
    "\n",
    "for memory in memories:\n",
    "    if counter == 0:\n",
    "        related_memory = memory.text\n",
    "    counter += 1\n",
    "    gathered_context.append(memory.text + \"\\n\")\n",
    "    print(f\"  > üò∂‚Äçüå´Ô∏è Hit {counter}: {memory.id} \")\n",
    "\n",
    "skillsDirectory = \"./plugins-sk\"\n",
    "print(f\"ü§ñ Synthesizing human-readable business-style presentation...\")\n",
    "pluginFC = kernel.import_semantic_skill_from_directory(skillsDirectory, \"FriendlyConsultant\");\n",
    "\n",
    "my_context = kernel.create_new_context()\n",
    "my_context['input'] = what_if_scenario\n",
    "my_context['context'] = \"\\n\".join(gathered_context)\n",
    "\n",
    "preso_result = await kernel.run_async(pluginFC[\"Presentation\"], input_context=my_context)\n",
    "\n",
    "display(Markdown(\"# ü§ñ Generated ...\\n\"+str(preso_result)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéóÔ∏è Let's review the key concepts here\n",
    "\n",
    "## üìò Quick business review\n",
    "\n",
    "Every business benefits from four courses of action to be used together or in combination:\n",
    "\n",
    "1. Grow the existing business\n",
    "2. Save money and time\n",
    "3. Add completely new business\n",
    "4. Prepare for the unknown\n",
    "\n",
    "![](assets/shopkeeper.png)\n",
    "\n",
    "The business owner is always leaking time and money from their valuable buckets of time and money. Let's help them succeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Quick tech review\n",
    "\n",
    "1. AI PLUGINs in SK enable encapsulating complex AI computations to be used on their own or to feed their results into other AI PLUGIN. \n",
    "2. AI memories, often called \"vector databases,\" can be used to hold information that is semantically searchable and can be leveraged as data to get fed into an AI PLUGIN.\n",
    "3. So-called \"hallucinations\" are reduced by building AI PLUGINs that process prompts with as much precision. And also by managing banks of semantic information to assemble and deepen contexts to feed into AI computations.\n",
    "4. AI PLUGINs and vector databases are used most effectively with AI PLANNERs. What's a PLANNER? We'll jump into that soon to give you a glimpse of the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
